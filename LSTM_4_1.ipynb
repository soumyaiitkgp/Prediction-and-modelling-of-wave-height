{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LSTM_4.1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soumyaiitkgp/Prediction-and-modelling-of-wave-height/blob/master/LSTM_4_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zTjwl4MtjP_K",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm_notebook\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras import optimizers\n",
        "from keras.callbacks import CSVLogger\n",
        "import os\n",
        "import logging\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
        "os.environ['TZ'] = 'Asia/Mumbai'  # to set timezone; needed when running on cloud\n",
        "time.tzset() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFov1ssU9bF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "czmWXv99k7R6",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('mehamn_data.csv', engine = 'python')\n",
        "print(data.shape)\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Nwbt_daglVld",
        "colab": {}
      },
      "source": [
        "params = {\n",
        "    \"batch_size\": 1440, #processing the information for 30 days at once\n",
        "    \"epochs\": 100,\n",
        "    \"lr\": 0.0001,\n",
        "    \"time_steps\": 120 #prediction for 15 days\n",
        "}\n",
        "\n",
        "iter_changes = \"dropout_layers_0.4_0.4\"\n",
        "\n",
        "TIME_STEPS = params[\"time_steps\"]\n",
        "BATCH_SIZE = params[\"batch_size\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H1Z71Bn8lZKM",
        "colab": {}
      },
      "source": [
        "for col in data.columns:\n",
        "    print(col)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sEDBnXh-ldOO",
        "colab": {}
      },
      "source": [
        "d = data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J-ynuolWlfi0",
        "colab": {}
      },
      "source": [
        "d_train,d_test = train_test_split(d,test_size=0.2, shuffle = False)\n",
        "print(d_train.shape, d_test.shape)\n",
        "d_train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "goT24ykLlgBe",
        "colab": {}
      },
      "source": [
        "print(d_test.shape)\n",
        "d_test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yl8qFaXXl3Ue",
        "colab": {}
      },
      "source": [
        "x_train = d_train\n",
        "x_test = d_test\n",
        "print(x_train.shape,x_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OY5RGotMl6Ad",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(x_train[\"total_sea_TP\"])\n",
        "plt.plot(x_train[\"total_sea_HS\"])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "49nDgC__l6mU",
        "colab": {}
      },
      "source": [
        "#train_cols = [\"Month\",\"Day\",\"Hour\", \"wind_WSP\",\"wind_DIR\",\"total_sea_TP\",\"total_sea_DIRP\",\"wind_sea_TP\",\"wind_sea_DIRP\",\"swell_TP\",\"swell_DIRP\"]\n",
        "min_max_scaler = MinMaxScaler()\n",
        "X_train = min_max_scaler.fit_transform(x_train)\n",
        "X_test = min_max_scaler.fit_transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ve0RUXV1l_IM",
        "colab": {}
      },
      "source": [
        "type(X_train)\n",
        "print(X_train.shape)\n",
        "plt.figure()\n",
        "plt.plot(X_train[0:,8])\n",
        "plt.plot(X_train[0:,7])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gss6oZNSl_qA",
        "colab": {}
      },
      "source": [
        "def build_timeseries(mat, y_col_index):\n",
        "    # y_col_index is the index of column that would act as output column, here it will be 9\n",
        "    # total number of time-series samples would be len(mat) - TIME_STEPS\n",
        "    #TIME_STEPS = 8 for one day\n",
        "    #LSTMs consume input in format [ batch_size, time_steps, Features ]; a 3- dimensional array.\n",
        "    #So till now we have a matrix of shape (3, 5), 3 being the time step and 5 being the number of features\n",
        "    dim_0 = mat.shape[0] - TIME_STEPS\n",
        "    dim_1 = mat.shape[1]\n",
        "    x = np.zeros((dim_0, TIME_STEPS, dim_1))\n",
        "    y = np.zeros((dim_0,))\n",
        "    print(dim_0,mat.shape[0])\n",
        "    for i in tqdm_notebook(range(dim_0)):\n",
        "        #print(i)\n",
        "        x[i] = mat[i:TIME_STEPS+i]\n",
        "        #print(mat[TIME_STEPS+i, y_col_index])\n",
        "        y[i] = mat[TIME_STEPS+i, y_col_index]\n",
        "    print(\"length of time-series i/o\",x.shape,y.shape)\n",
        "    return x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kYfQ4ui7mBZZ",
        "colab": {}
      },
      "source": [
        "def trim_dataset(mat, batch_size):\n",
        "    \"\"\"\n",
        "    trims dataset to a size that's divisible by BATCH_SIZE\n",
        "    \"\"\"\n",
        "    no_of_rows_drop = mat.shape[0]%batch_size\n",
        "    if(no_of_rows_drop > 0):\n",
        "        return mat[:-no_of_rows_drop]\n",
        "    else:\n",
        "        return mat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m0LHwgDrmDf0",
        "colab": {}
      },
      "source": [
        "x_t, y_t = build_timeseries(X_train, 9)\n",
        "x_t = trim_dataset(x_t, BATCH_SIZE)\n",
        "y_t = trim_dataset(y_t, BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "20BGooE8mFNI",
        "colab": {}
      },
      "source": [
        "x_temp, y_temp = build_timeseries(X_test, 9)\n",
        "x_tt = trim_dataset(x_temp, BATCH_SIZE)\n",
        "y_tt = trim_dataset(y_temp, BATCH_SIZE)\n",
        "print(y_tt.shape)\n",
        "print(x_tt.shape)\n",
        "x_val, x_test_t = np.split(x_tt,2)\n",
        "y_val, y_test_t = np.split(y_tt,2)\n",
        "print(x_val.shape, x_test_t.shape)\n",
        "print(y_val.shape, y_test_t.shape)\n",
        "#x_val, x_test_t = np.split(trim_dataset(x_temp, BATCH_SIZE),2)\n",
        "#y_val, y_test_t = np.split(trim_dataset(y_temp, BATCH_SIZE),2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t601e8d9mIJX",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "lstm_model = Sequential()\n",
        "lstm_model.add(LSTM(64, batch_input_shape=(BATCH_SIZE, TIME_STEPS, x_t.shape[2]), dropout=0.0, recurrent_dropout=0.0, stateful=True, return_state=True, kernel_initializer='random_uniform'))\n",
        "lstm_model.add(Dropout(0.2)) \n",
        "print(0)\n",
        "lstm_model.add(LSTM(128, return_state=True))\n",
        "lstm_model.add(Dropout(0.2)) \n",
        "print(1)\n",
        "lstm_model.add(LSTM(256, return_state=True))\n",
        "lstm_model.add(Dropout(0.2)) \n",
        "print(2)\n",
        "lstm_model.add(LSTM(128, return_state=True))\n",
        "lstm_model.add(Dropout(0.2)) \n",
        "print(3)\n",
        "lstm_model.add(LSTM(64))\n",
        "print(4)\n",
        "lstm_model.add(Dense(20,activation='relu'))\n",
        "lstm_model.add(Dense(1,activation='sigmoid'))\n",
        "optimizer = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "lstm_model.compile(loss='mean_squared_error', optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lj9HGH5dmKLR",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "OUTPUT_PATH = \"D:\\Acads\\Saud sir\"\n",
        "csv_logger = CSVLogger(os.path.join(OUTPUT_PATH, 'your_log_name' + '.log'), append=True)\n",
        "\n",
        "history = lstm_model.fit(x_t, y_t, epochs=25, verbose=2, batch_size=BATCH_SIZE,\n",
        "                    shuffle=False, validation_data=(trim_dataset(x_val, BATCH_SIZE),\n",
        "                    trim_dataset(y_val, BATCH_SIZE)))#, callbacks=[csv_logger])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zboWLd2FmOMS",
        "colab": {}
      },
      "source": [
        "# model.evaluate(x_test_t, y_test_t, batch_size=BATCH_SIZE\n",
        "from sklearn.metrics import mean_squared_error\n",
        "y_pred = lstm_model.predict(trim_dataset(x_test_t, BATCH_SIZE), batch_size=BATCH_SIZE)\n",
        "y_pred = y_pred.flatten()\n",
        "y_test_t = trim_dataset(y_test_t, BATCH_SIZE)\n",
        "error = mean_squared_error(y_test_t, y_pred)\n",
        "print(\"Error is\", error, y_pred.shape, y_test_t.shape)\n",
        "print(y_pred[0:15])\n",
        "print(y_test_t[0:15])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iMoQXl3UmZ79",
        "colab": {}
      },
      "source": [
        "# convert the predicted value to range of real data\n",
        "y_pred_org = (y_pred * min_max_scaler.data_range_[9]) + min_max_scaler.data_min_[9]\n",
        "# min_max_scaler.inverse_transform(y_pred)\n",
        "y_test_t_org = (y_test_t * min_max_scaler.data_range_[9]) + min_max_scaler.data_min_[9]\n",
        "# min_max_scaler.inverse_transform(y_test_t)\n",
        "print(y_pred_org[0:15])\n",
        "print(y_test_t_org[0:15])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vtvlek8omcL_",
        "colab": {}
      },
      "source": [
        "# Visualize the training data\n",
        "from matplotlib import pyplot as plt\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "#plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m52xOfNQmdtg",
        "colab": {}
      },
      "source": [
        "y_pred = lstm_model.predict(trim_dataset(x_test_t, BATCH_SIZE), batch_size=BATCH_SIZE)\n",
        "y_pred = y_pred.flatten()\n",
        "#y_test_t = trim_dataset(y_test_t, BATCH_SIZE)\n",
        "error = mean_squared_error(y_test_t, y_pred)\n",
        "print(\"Error is\", error, y_pred.shape, y_test_t.shape)\n",
        "print(y_pred[0:15])\n",
        "print(y_test_t[0:15])\n",
        "y_pred_org = (y_pred * min_max_scaler.data_range_[9]) + min_max_scaler.data_min_[9] # min_max_scaler.inverse_transform(y_pred)\n",
        "y_test_t_org = (y_test_t * min_max_scaler.data_range_[9]) + min_max_scaler.data_min_[9] # min_max_scaler.inverse_transform(y_test_t)\n",
        "print(y_pred_org[100:200])\n",
        "print(y_test_t_org[100:200])\n",
        "\n",
        "# Visualize the prediction\n",
        "from matplotlib import pyplot as plt\n",
        "plt.figure()\n",
        "#plt.plot(y_test_t_org)\n",
        "#plt.plot(y_pred_org)\n",
        "\n",
        "plt.plot(y_pred_org[0:100])\n",
        "plt.plot(y_test_t_org[0:100])\n",
        "plt.plot()\n",
        "plt.title('Prediction vs Real Stock Price')\n",
        "plt.ylabel('Price')\n",
        "plt.xlabel('Days')\n",
        "plt.legend(['Prediction', 'Real'], loc='upper left')\n",
        "plt.show()\n",
        "print(\"batch_size = \",BATCH_SIZE ,\"timesteps =\",TIME_STEPS , \"lr = 0.001\",\"optimizer = Adam\", \"No of LSTM layers =2\",\"Dropout=0.4\",\"stateful=True \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OlUH8-NGmfyk",
        "colab": {}
      },
      "source": [
        "# Visualize the prediction\n",
        "from matplotlib import pyplot as plt\n",
        "plt.figure()\n",
        "#plt.plot(y_test_t_org)\n",
        "#plt.plot(y_pred_org)\n",
        "\n",
        "plt.plot(y_pred_org[0:100])\n",
        "plt.plot(y_test_t_org[0:100])\n",
        "plt.plot()\n",
        "plt.title('Prediction vs Real Stock Price')\n",
        "plt.ylabel('Price')\n",
        "plt.xlabel('Days')\n",
        "plt.legend(['Prediction', 'Real'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ugUYImFBmigd",
        "colab": {}
      },
      "source": [
        "# Visualize the prediction\n",
        "from matplotlib import pyplot as plt\n",
        "plt.figure()\n",
        "#plt.plot(y_test_t_org)\n",
        "#plt.plot(y_pred_org)\n",
        "\n",
        "plt.plot(y_pred_org[0:100])\n",
        "plt.plot(y_test_t_org[0:100])\n",
        "plt.plot()\n",
        "plt.title('Prediction vs Real Stock Price')\n",
        "plt.ylabel('Price')\n",
        "plt.xlabel('Days')\n",
        "plt.legend(['Prediction', 'Real'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjnUIZiF9Gni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(175):\n",
        "    plt.figure()\n",
        "    plt.plot()\n",
        "    plt.ylim(top = 12)\n",
        "    plt.plot(y_pred_org[i*100:i*100 + 100])\n",
        "    plt.plot(y_test_t_org[i*100:i*100 + 100])\n",
        "    plt.plot()\n",
        "    plt.title('Prediction vs wave height')\n",
        "    plt.ylabel('Wave height')\n",
        "    plt.xlabel('Number')\n",
        "    plt.legend(['Prediction', 'Real'], loc='upper left')\n",
        "    #from google.colab import files\n",
        "    from google.colab import files\n",
        "    plt.savefig('Plot'+ str(i)+'0'+'(LSTM_4.1)'+'.png')\n",
        "    files.download('Plot'+ str(i)+'0'+'(LSTM_4.1)'+'.png')\n",
        "    #plt.savefig('Plot'+ str(i)+'0'+'(LSTM_4.1)'+'.png')\n",
        "    #files.download('Plot'+ str(i)+'0'+'(LSTM_4.1)'+'.png')\n",
        "    plt.show()\n",
        "    \n",
        "    plt.figure()\n",
        "    plt.plot()\n",
        "    plt.ylim(top = 12)\n",
        "    plt.plot(y_pred_org[50+i*100:i*100 + 150])\n",
        "    plt.plot(y_test_t_org[50+i*100:i*100 + 150])\n",
        "    plt.plot()\n",
        "    plt.title('Prediction vs wave height')\n",
        "    plt.ylabel('Wave height')\n",
        "    plt.xlabel('Number')\n",
        "    plt.legend(['Prediction', 'Real'], loc='upper left')\n",
        "    #from google.colab import files\n",
        "    from google.colab import files\n",
        "    plt.savefig('Plot'+ str(i)+'1'+'(LSTM_4.1)'+'.png')\n",
        "    files.download('Plot'+ str(i)+'1'+'(LSTM_4.1)'+'.png')\n",
        "    #plt.savefig('Plot'+ str(i)+'1'+'(LSTM_4.1)'+'.png')\n",
        "    #files.download('Plot'+ str(i)+'0'+'(LSTM_4.1)'+'.png')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ewJGOICsmrL1",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(y_test_t - y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WjgRDlTumr12",
        "colab": {}
      },
      "source": [
        "print(max(y_test_t - y_pred))\n",
        "print(min(y_test_t - y_pred))\n",
        "print(type(y_test_t - y_pred))\n",
        "print(np.mean(y_test_t - y_pred))\n",
        "print(np.std(y_test_t - y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1_Xyl719Gnw",
        "colab_type": "text"
      },
      "source": [
        "Max error: 0.4540718008490169\n",
        "Min error: -0.2863886167021359\n",
        "Average: -0.0006845318656293139\n",
        "Standard deviation: 0.05870196666310056\n",
        "Error is 0.003446389473990832"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7QPgSDyM-uG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}